{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAG Components (Store → Retriever → Generator)\n","metadata":{}},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:32:45.013042Z","iopub.execute_input":"2026-02-16T09:32:45.013234Z","iopub.status.idle":"2026-02-16T09:32:51.581092Z","shell.execute_reply.started":"2026-02-16T09:32:45.013214Z","shell.execute_reply":"2026-02-16T09:32:51.580359Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0rc2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import List, Dict, Any\nimport numpy as np\n\n\nfrom sentence_transformers import SentenceTransformer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:32:51.583160Z","iopub.execute_input":"2026-02-16T09:32:51.583417Z","iopub.status.idle":"2026-02-16T09:33:22.627600Z","shell.execute_reply.started":"2026-02-16T09:32:51.583391Z","shell.execute_reply":"2026-02-16T09:33:22.627020Z"}},"outputs":[{"name":"stderr","text":"2026-02-16 09:33:05.576285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771234385.764334      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771234385.821167      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771234386.272308      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771234386.272354      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771234386.272357      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771234386.272360      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_id = \"Qwen/Qwen3-8B\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:33:22.631177Z","iopub.execute_input":"2026-02-16T09:33:22.631471Z","iopub.status.idle":"2026-02-16T09:33:22.635804Z","shell.execute_reply.started":"2026-02-16T09:33:22.631448Z","shell.execute_reply":"2026-02-16T09:33:22.634988Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:33:22.636772Z","iopub.execute_input":"2026-02-16T09:33:22.637097Z","iopub.status.idle":"2026-02-16T09:33:24.350809Z","shell.execute_reply.started":"2026-02-16T09:33:22.637067Z","shell.execute_reply":"2026-02-16T09:33:24.349933Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16b186cd7984eeaab79b9cdab0b0fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22976bad09464c71a6d006375f2c6d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300b529e641645cd8686b403b456e2e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e91ca42d83041beb40a6282204ad728"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    dtype=torch.float16,\n    load_in_4bit=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:33:24.351819Z","iopub.execute_input":"2026-02-16T09:33:24.352137Z","iopub.status.idle":"2026-02-16T09:35:01.820982Z","shell.execute_reply.started":"2026-02-16T09:33:24.352100Z","shell.execute_reply":"2026-02-16T09:35:01.820151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eca2b015b17424588b85a75219e90f0"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc02600eca14826b17ec0819c6e7803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3019a747f8d4793be6711524f0917c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ef87b52d59440693b10899de20b813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"317730e1da9d452d8e63de7bb8baaf61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bec23070c4f4b93ab507877450b92e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16f4d0d7ba64db784104dce31237d96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3660ae8eb3e94fc2b0972729e3939f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b18536efbe4d138647dcf2e5ac21c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c49d2050b5e491aaeb77af4b5eb0ac6"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:37:04.619750Z","iopub.execute_input":"2026-02-16T09:37:04.620461Z","iopub.status.idle":"2026-02-16T09:37:04.626911Z","shell.execute_reply.started":"2026-02-16T09:37:04.620431Z","shell.execute_reply":"2026-02-16T09:37:04.625981Z"}},"outputs":[{"name":"stdout","text":"Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 4096)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"@dataclass\nclass Doc:\n    text: str\n    meta: Dict[str, Any] | None = None\n\nclass Store:\n    \"\"\"Stores docs + their sentence embeddings computed at add() time.\"\"\"\n    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n        self.model = SentenceTransformer(model_name)\n        self.docs: List[Doc] = []\n        self.E = None  # (N, d) numpy array of normalized embeddings\n\n    def add(self, text: str, meta: Dict[str, Any] | None = None):\n        e = self.model.encode([text], normalize_embeddings=True)[0]  # (d,)\n        self.docs.append(Doc(text=text, meta=meta))\n        self.E = e[None, :] if self.E is None else np.vstack([self.E, e])\n\n    def embed_query(self, query: str):\n        return self.model.encode([query], normalize_embeddings=True)[0]  # (d,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:01.823450Z","iopub.execute_input":"2026-02-16T09:35:01.824143Z","iopub.status.idle":"2026-02-16T09:35:01.832242Z","shell.execute_reply.started":"2026-02-16T09:35:01.824116Z","shell.execute_reply":"2026-02-16T09:35:01.831217Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nclass Retriever:\n    \"\"\"Only retrieves from an existing Store. Does NOT build/update the index.\"\"\"\n    def __init__(self, store: Store):\n        self.store = store\n\n    def retrieve(self, query: str, k: int = 3):\n        if self.store.E is None:\n            return []\n        q = self.store.embed_query(query)                 # query vector (no index update)\n        scores = (self.store.E @ q.T).ravel()   # cosine similarity\n        top_idx = np.argsort(-scores)[:k]\n        return [(scores[i], self.store.docs[i]) for i in top_idx]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:01.833240Z","iopub.execute_input":"2026-02-16T09:35:01.833781Z","iopub.status.idle":"2026-02-16T09:35:01.844806Z","shell.execute_reply.started":"2026-02-16T09:35:01.833749Z","shell.execute_reply":"2026-02-16T09:35:01.843998Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Generator:\n    \"\"\"Shows context injection. (Replace with a real LLM later.)\"\"\"\n    def generate(self, query, retrieved: List[Doc], max_new_tokens=256):\n        \n        prompt = f\"\"\"You are a helpful assistant. Use ONLY the context.\n    \n        Context:\n        {chr(10).join([f\"- {c}\" for c in retrieved])}\n        \n        Question: {query}\"\"\"\n\n        \n        messages = [\n        {\"role\": \"user\", \"content\": prompt}\n        ]\n        text = tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True,\n            enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n        )\n        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n        \n        # conduct text completion\n        generated_ids = model.generate(\n            **model_inputs,\n            max_new_tokens=32768\n        )\n        output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n        #inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        return tokenizer.decode(output_ids, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:01.845772Z","iopub.execute_input":"2026-02-16T09:35:01.846099Z","iopub.status.idle":"2026-02-16T09:35:01.858494Z","shell.execute_reply.started":"2026-02-16T09:35:01.846064Z","shell.execute_reply":"2026-02-16T09:35:01.857717Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# --- 1) Add documents to the Store (representations are saved at add time) ---\n\nstore = Store()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:01.859331Z","iopub.execute_input":"2026-02-16T09:35:01.859679Z","iopub.status.idle":"2026-02-16T09:35:04.163054Z","shell.execute_reply.started":"2026-02-16T09:35:01.859626Z","shell.execute_reply":"2026-02-16T09:35:04.162255Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac4b99ee0b914b6ea8f1b5f72e1ffa18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd1a86686bb4c5c9c451b57549cc119"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad19318b4954c3ebd3c4b47683e805d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c44a0e1cfc7463e8ab9c7590b77f3a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b34b03ed72e45e3bce41536e06ef429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62f56ff8ae8641e7ba829b0f4dbe49d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd57c67e38542b1b296dc6c439a7d0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c4fffec5414ec0b7d309a026f9e8e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c179f50d95046408a431006d417d8a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a59a115539470e83375d900e5c7776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21c46f79c7f74a8691819738e20f47ec"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"store.add(\"RAG retrieves relevant documents at query time and uses them to generate grounded answers.\", \n          meta={\"source\": \"intro\"})\n\nstore.add(\"A vector store holds document embeddings so similarity search can retrieve the most relevant chunks.\", \n          meta={\"source\": \"store\"})\n\nstore.add(\"A retriever selects top-k relevant chunks for a query using lexical, dense, or hybrid search.\", \n          meta={\"source\": \"retriever\"})\n\nstore.add(\"The generator (LLM) reads the retrieved context and produces an answer, ideally with citations.\", \n          meta={\"source\": \"generator\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:04.164014Z","iopub.execute_input":"2026-02-16T09:35:04.164231Z","iopub.status.idle":"2026-02-16T09:35:04.584538Z","shell.execute_reply.started":"2026-02-16T09:35:04.164207Z","shell.execute_reply":"2026-02-16T09:35:04.583892Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"len(store.docs), store.E.shape ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:04.585509Z","iopub.execute_input":"2026-02-16T09:35:04.585782Z","iopub.status.idle":"2026-02-16T09:35:04.591935Z","shell.execute_reply.started":"2026-02-16T09:35:04.585748Z","shell.execute_reply":"2026-02-16T09:35:04.591125Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(4, (4, 384))"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"\nretriever = Retriever(store)\n\nquery = \"Is pre-approval needed for a ₹18k course, and when do I have to submit the claim?\"\nhits = retriever.retrieve(query, k=3)\n\nfor score, doc in hits:\n    print(f\"score={score:.3f} | source={doc.meta.get('source') if doc.meta else None}\\n  {doc.text}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:04.593018Z","iopub.execute_input":"2026-02-16T09:35:04.593390Z","iopub.status.idle":"2026-02-16T09:35:04.616429Z","shell.execute_reply.started":"2026-02-16T09:35:04.593356Z","shell.execute_reply":"2026-02-16T09:35:04.615711Z"}},"outputs":[{"name":"stdout","text":"score=0.034 | source=generator\n  The generator (LLM) reads the retrieved context and produces an answer, ideally with citations.\n\nscore=0.014 | source=intro\n  RAG retrieves relevant documents at query time and uses them to generate grounded answers.\n\nscore=-0.063 | source=retriever\n  A retriever selects top-k relevant chunks for a query using lexical, dense, or hybrid search.\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# --- 3) Generate by injecting retrieved docs into context ---\n\ngen = Generator()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:04.617450Z","iopub.execute_input":"2026-02-16T09:35:04.617747Z","iopub.status.idle":"2026-02-16T09:35:04.622197Z","shell.execute_reply.started":"2026-02-16T09:35:04.617711Z","shell.execute_reply":"2026-02-16T09:35:04.621363Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"answer = gen.generate(query, [d for _, d in hits])\nanswer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:04.623187Z","iopub.execute_input":"2026-02-16T09:35:04.623490Z","iopub.status.idle":"2026-02-16T09:35:12.058123Z","shell.execute_reply.started":"2026-02-16T09:35:04.623458Z","shell.execute_reply":"2026-02-16T09:35:12.057246Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'Based on the provided context, there is no information related to pre-approval requirements for a ₹18k course or the submission deadlines for claims. The context documents discuss topics related to retrieval and generation processes in a system, but they do not address financial or administrative procedures. Therefore, I cannot provide an answer to the question using the given context.'"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"store.add(\n  \"Learning & Certification Policy (Internal, v2026.01): \"\n  \"Employees may claim reimbursement for job-relevant online courses and certification exam fees. \"\n  \"Pre-approval is required if the total cost exceeds ₹10,000 (course + exam). \"\n  \"Reimbursement caps: ₹30,000 per employee per financial year. \"\n  \"Required proof: paid invoice/receipt, course completion certificate (or exam result), and approval email if applicable. \"\n  \"Claims must be submitted within 14 calendar days of completion.\",\n  meta={\"source\": \"policy/learning-certification\"}\n)\n\nstore.add(\n  \"Finance Claims SOP (Internal): \"\n  \"Submit reimbursements in the Expense Portal under category 'Learning & Development'. \"\n  \"Mandatory fields: cost center, project code (if applicable), vendor name, invoice date, and currency. \"\n  \"Attach receipts as a single PDF. Approval flow: Manager → Finance. \"\n  \"Common rejection reasons: missing receipt, missing completion proof, incorrect category, or missing cost center. \"\n  \"Typical processing time: 4–6 business days after final approval.\",\n  meta={\"source\": \"sop/finance-claims\"}\n)\n\nstore.add(\n  \"Procurement Guidelines (Internal): \"\n  \"For software subscriptions or licenses, request via Procurement Form before purchase if the vendor requires a contract. \"\n  \"Include: license count, duration, cost, business justification, and vendor quote. \"\n  \"Approvals: Budget Owner → Procurement. \"\n  \"For renewals, submit request at least 10 business days before expiry.\",\n  meta={\"source\": \"guidelines/procurement\"}\n)\n\nstore.add(\n  \"IT Access & Tool Request Guide (Internal): \"\n  \"Access requests are handled through the IT Service Desk. \"\n  \"Provide: tool name, purpose, team, duration, and required access level (viewer/editor/admin). \"\n  \"Turnaround: 1–3 business days for standard tools; longer if license purchase is needed. \"\n  \"Admins are granted only with manager approval and justification.\",\n  meta={\"source\": \"guide/it-access-tooling\"}\n)\n\nstore.add(\n  \"Information Handling Basics (Internal): \"\n  \"Share files using approved company storage with access controls (no public links). \"\n  \"Avoid storing secrets in documents; use the secrets manager. \"\n  \"If sharing data externally (vendor/partner), ensure a data-sharing agreement is in place and share only the minimum necessary. \"\n  \"Remove direct identifiers when not required for the task.\",\n  meta={\"source\": \"policy/info-handling\"}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:12.059126Z","iopub.execute_input":"2026-02-16T09:35:12.059522Z","iopub.status.idle":"2026-02-16T09:35:12.103485Z","shell.execute_reply.started":"2026-02-16T09:35:12.059494Z","shell.execute_reply":"2026-02-16T09:35:12.102734Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"hits = retriever.retrieve(query, k=3)\n\nfor score, doc in hits:\n    print(f\"score={score:.3f} | source={doc.meta.get('source') if doc.meta else None}\\n  {doc.text}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:12.104438Z","iopub.execute_input":"2026-02-16T09:35:12.104830Z","iopub.status.idle":"2026-02-16T09:35:12.117220Z","shell.execute_reply.started":"2026-02-16T09:35:12.104796Z","shell.execute_reply":"2026-02-16T09:35:12.116395Z"}},"outputs":[{"name":"stdout","text":"score=0.634 | source=policy/learning-certification\n  Learning & Certification Policy (Internal, v2026.01): Employees may claim reimbursement for job-relevant online courses and certification exam fees. Pre-approval is required if the total cost exceeds ₹10,000 (course + exam). Reimbursement caps: ₹30,000 per employee per financial year. Required proof: paid invoice/receipt, course completion certificate (or exam result), and approval email if applicable. Claims must be submitted within 14 calendar days of completion.\n\nscore=0.566 | source=sop/finance-claims\n  Finance Claims SOP (Internal): Submit reimbursements in the Expense Portal under category 'Learning & Development'. Mandatory fields: cost center, project code (if applicable), vendor name, invoice date, and currency. Attach receipts as a single PDF. Approval flow: Manager → Finance. Common rejection reasons: missing receipt, missing completion proof, incorrect category, or missing cost center. Typical processing time: 4–6 business days after final approval.\n\nscore=0.389 | source=guidelines/procurement\n  Procurement Guidelines (Internal): For software subscriptions or licenses, request via Procurement Form before purchase if the vendor requires a contract. Include: license count, duration, cost, business justification, and vendor quote. Approvals: Budget Owner → Procurement. For renewals, submit request at least 10 business days before expiry.\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"answer = gen.generate(query, [d for _, d in hits])\nanswer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T09:35:12.118345Z","iopub.execute_input":"2026-02-16T09:35:12.118762Z","iopub.status.idle":"2026-02-16T09:35:17.206665Z","shell.execute_reply.started":"2026-02-16T09:35:12.118722Z","shell.execute_reply":"2026-02-16T09:35:17.205910Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'Yes, pre-approval is needed for a ₹18,000 course, as the total cost exceeds ₹10,000. You must submit the claim within 14 calendar days of completing the course.'"},"metadata":{}}],"execution_count":17}]}